{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a2a5f13",
   "metadata": {},
   "source": [
    "# Day 11: RAG ‚Äî Retrieval-Augmented Generation\n",
    "\n",
    "LLMs are powerful, but they have a problem:\n",
    "\n",
    "They don't know **your** data.\n",
    "\n",
    "**RAG** solves this: retrieve relevant context first, then generate a response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6bf41d",
   "metadata": {},
   "source": [
    "## The RAG Pipeline\n",
    "\n",
    "```\n",
    "User Query ‚Üí Embed ‚Üí Search Documents ‚Üí Retrieve Top-K ‚Üí Send to LLM ‚Üí Response\n",
    "```\n",
    "\n",
    "The LLM generates answers **grounded** in your documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925770d1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b1a1140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "API_KEY = os.environ[\"GEMINI_API_KEY\"]\n",
    "client = genai.Client(api_key=API_KEY)\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f42f84d",
   "metadata": {},
   "source": [
    "## Knowledge Base\n",
    "\n",
    "Our \"private data\" ‚Äî information the LLM doesn't know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2097ac37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Knowledge Base:\n",
      "  1. Our company's refund policy allows returns within 30 days of purchase.\n",
      "  2. Premium members get free shipping on all orders over $25.\n",
      "  3. Customer support is available Monday to Friday, 9 AM to 6 PM EST.\n",
      "  4. Gift cards can be purchased in denominations of $25, $50, and $100.\n",
      "  5. Orders are typically delivered within 3-5 business days.\n"
     ]
    }
   ],
   "source": [
    "knowledge_base = [\n",
    "    \"Our company's refund policy allows returns within 30 days of purchase.\",\n",
    "    \"Premium members get free shipping on all orders over $25.\",\n",
    "    \"Customer support is available Monday to Friday, 9 AM to 6 PM EST.\",\n",
    "    \"Gift cards can be purchased in denominations of $25, $50, and $100.\",\n",
    "    \"Orders are typically delivered within 3-5 business days.\"\n",
    "]\n",
    "\n",
    "print(\"üìö Knowledge Base:\")\n",
    "for i, doc in enumerate(knowledge_base):\n",
    "    print(f\"  {i+1}. {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde73f6d",
   "metadata": {},
   "source": [
    "## Index the Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5efdc97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Indexed 5 documents\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for all documents\n",
    "kb_embeddings = []\n",
    "for doc in knowledge_base:\n",
    "    response = client.models.embed_content(\n",
    "        model=\"gemini-embedding-001\",\n",
    "        contents=doc\n",
    "    )\n",
    "    kb_embeddings.append(response.embeddings[0].values)\n",
    "\n",
    "print(f\"‚úÖ Indexed {len(kb_embeddings)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc673fe3",
   "metadata": {},
   "source": [
    "## Retrieval Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4afd89e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, top_k=2):\n",
    "    \"\"\"Find the most relevant documents for a query.\"\"\"\n",
    "    query_response = client.models.embed_content(\n",
    "        model=\"gemini-embedding-001\",\n",
    "        contents=query\n",
    "    )\n",
    "    query_embedding = query_response.embeddings[0].values\n",
    "    \n",
    "    scores = []\n",
    "    for i, doc_emb in enumerate(kb_embeddings):\n",
    "        similarity = cosine_similarity(query_embedding, doc_emb)\n",
    "        scores.append((similarity, i))\n",
    "    \n",
    "    scores.sort(reverse=True)\n",
    "    \n",
    "    return [knowledge_base[idx] for _, idx in scores[:top_k]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f779905",
   "metadata": {},
   "source": [
    "## RAG Function\n",
    "\n",
    "This is the core: **Retrieve** context, then **Generate** a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e002fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    \"\"\"Retrieval-Augmented Generation.\"\"\"\n",
    "    \n",
    "    # Step 1: Retrieve relevant documents\n",
    "    relevant_docs = retrieve(query, top_k=2)\n",
    "    \n",
    "    # Step 2: Build the context\n",
    "    context = \"\\n\".join(f\"- {doc}\" for doc in relevant_docs)\n",
    "    \n",
    "    # Step 3: Create the prompt with context\n",
    "    prompt = f\"\"\"Answer the user's question based ONLY on the following context.\n",
    "If the answer is not in the context, say \"I don't have that information.\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    # Step 4: Generate response\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        contents=prompt\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"answer\": response.text,\n",
    "        \"sources\": relevant_docs\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67252d8b",
   "metadata": {},
   "source": [
    "## Test: Question About Refunds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd3e80bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì Question: Can I return a product I bought 2 weeks ago?\n",
      "\n",
      "üí¨ Answer: Yes, you can return a product you bought 2 weeks ago.\n",
      "\n",
      "üìÑ Sources:\n",
      "  ‚Ä¢ Our company's refund policy allows returns within 30 days of purchase.\n",
      "  ‚Ä¢ Orders are typically delivered within 3-5 business days.\n"
     ]
    }
   ],
   "source": [
    "query = \"Can I return a product I bought 2 weeks ago?\"\n",
    "\n",
    "print(f\"‚ùì Question: {query}\\n\")\n",
    "result = rag(query)\n",
    "\n",
    "print(f\"üí¨ Answer: {result['answer']}\")\n",
    "print(f\"\\nüìÑ Sources:\")\n",
    "for doc in result['sources']:\n",
    "    print(f\"  ‚Ä¢ {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4152fde2",
   "metadata": {},
   "source": [
    "## Test: Question About Shipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1b2c3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì Question: How long does shipping take?\n",
      "\n",
      "üí¨ Answer: Orders are typically delivered within 3-5 business days.\n",
      "\n",
      "üìÑ Sources:\n",
      "  ‚Ä¢ Orders are typically delivered within 3-5 business days.\n",
      "  ‚Ä¢ Premium members get free shipping on all orders over $25.\n"
     ]
    }
   ],
   "source": [
    "query = \"How long does shipping take?\"\n",
    "\n",
    "print(f\"‚ùì Question: {query}\\n\")\n",
    "result = rag(query)\n",
    "\n",
    "print(f\"üí¨ Answer: {result['answer']}\")\n",
    "print(f\"\\nüìÑ Sources:\")\n",
    "for doc in result['sources']:\n",
    "    print(f\"  ‚Ä¢ {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5",
   "metadata": {},
   "source": [
    "## Test: Question Not in Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c3d4e5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì Question: What is the capital of France?\n",
      "\n",
      "üí¨ Answer: I don't have that information.\n",
      "\n",
      "üìÑ Sources (retrieved but not relevant):\n",
      "  ‚Ä¢ Customer support is available Monday to Friday, 9 AM to 6 PM EST.\n",
      "  ‚Ä¢ Orders are typically delivered within 3-5 business days.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the capital of France?\"\n",
    "\n",
    "print(f\"‚ùì Question: {query}\\n\")\n",
    "result = rag(query)\n",
    "\n",
    "print(f\"üí¨ Answer: {result['answer']}\")\n",
    "print(f\"\\nüìÑ Sources (retrieved but not relevant):\")\n",
    "for doc in result['sources']:\n",
    "    print(f\"  ‚Ä¢ {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "## Why RAG Works\n",
    "\n",
    "1. **Grounded Responses** ‚Äî Answers based on actual data, not hallucinations\n",
    "2. **Up-to-date** ‚Äî Just update the knowledge base, no retraining\n",
    "3. **Transparent** ‚Äî You can show the sources used\n",
    "4. **Private** ‚Äî Your data stays in your system\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **RAG = Retrieve + Generate**\n",
    "2. Embed and index your documents **once**\n",
    "3. For each query: retrieve relevant context, then prompt the LLM\n",
    "4. Always provide sources for transparency\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** Day 12 ‚Äî Chunking: Handling large documents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
