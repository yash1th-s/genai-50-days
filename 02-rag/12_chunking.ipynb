{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a2a5f13",
   "metadata": {},
   "source": [
    "# Day 12: Chunking â€” Handling Large Documents\n",
    "\n",
    "RAG works great with short documents.\n",
    "\n",
    "But what about a 50-page PDF?\n",
    "\n",
    "You can't embed it as one unit. You need to **chunk** it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925770d1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b1a1140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "API_KEY = os.environ[\"GEMINI_API_KEY\"]\n",
    "client = genai.Client(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f42f84d",
   "metadata": {},
   "source": [
    "## A Long Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2097ac37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: 637 characters, ~84 words\n"
     ]
    }
   ],
   "source": [
    "long_document = \"\"\"\n",
    "Machine Learning: A Comprehensive Overview\n",
    "\n",
    "Machine learning is a subset of artificial intelligence that enables computers to learn from data without being explicitly programmed.\n",
    "\n",
    "Supervised learning uses labeled data. The algorithm learns to map inputs to known outputs. Common applications include spam detection and image classification.\n",
    "\n",
    "Unsupervised learning works with unlabeled data. The algorithm finds hidden patterns. Common applications include customer segmentation and anomaly detection.\n",
    "\n",
    "Reinforcement learning involves an agent learning through trial and error. The agent takes actions and receives rewards or penalties.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Document: {len(long_document)} characters, ~{len(long_document.split())} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde73f6d",
   "metadata": {},
   "source": [
    "## Chunking by Paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5efdc97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 5 chunks:\n",
      "\n",
      "Chunk 1: Machine Learning: A Comprehensive Overview...\n",
      "Chunk 2: Machine learning is a subset of artificial intelligence that...\n",
      "Chunk 3: Supervised learning uses labeled data. The algorithm learns ...\n",
      "Chunk 4: Unsupervised learning works with unlabeled data. The algorit...\n",
      "Chunk 5: Reinforcement learning involves an agent learning through tr...\n"
     ]
    }
   ],
   "source": [
    "def chunk_by_paragraph(text):\n",
    "    \"\"\"Split text into paragraph-based chunks.\"\"\"\n",
    "    paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n",
    "    return paragraphs\n",
    "\n",
    "chunks = chunk_by_paragraph(long_document)\n",
    "\n",
    "print(f\"Created {len(chunks)} chunks:\\n\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1}: {chunk[:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc673fe3",
   "metadata": {},
   "source": [
    "## Index and Search Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4afd89e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Indexed 5 chunks\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    vec1, vec2 = np.array(vec1), np.array(vec2)\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "# Index all chunks\n",
    "chunk_embeddings = []\n",
    "for chunk in chunks:\n",
    "    response = client.models.embed_content(model=\"gemini-embedding-001\", contents=chunk)\n",
    "    chunk_embeddings.append(response.embeddings[0].values)\n",
    "\n",
    "print(f\"âœ… Indexed {len(chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e002fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Ž Query: 'How does an AI agent learn from rewards?'\n",
      "\n",
      "Best match: Reinforcement learning involves an agent learning through trial and error. The agent takes actions and receives rewards or penalties.\n"
     ]
    }
   ],
   "source": [
    "# Search\n",
    "query = \"How does an AI agent learn from rewards?\"\n",
    "\n",
    "query_emb = client.models.embed_content(model=\"gemini-embedding-001\", contents=query).embeddings[0].values\n",
    "\n",
    "scores = [(cosine_similarity(query_emb, emb), i) for i, emb in enumerate(chunk_embeddings)]\n",
    "scores.sort(reverse=True)\n",
    "\n",
    "print(f\"ðŸ”Ž Query: '{query}'\\n\")\n",
    "print(f\"Best match: {chunks[scores[0][1]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. Long documents need **chunking** before embedding\n",
    "2. Each chunk gets its own embedding\n",
    "3. Search finds the **relevant chunk**, not the whole document\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** Day 13 â€” Vector Databases"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
