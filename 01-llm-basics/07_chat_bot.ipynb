{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a2a5f13",
   "metadata": {},
   "source": [
    "## Budget-Aware Chatbot (Using Real Gemini Token Counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b1a1140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "API_KEY = os.environ[\"GEMINI_API_KEY2\"]\n",
    "client = genai.Client(api_key=API_KEY)\n",
    "model_name = \"gemini-2.5-flash\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6bf41d",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d7d6362",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_INSTRUCTION = \"\"\"\n",
    "You are a senior AI tutor helping developers understand technical concepts.\n",
    "\n",
    "Rules:\n",
    "- Be concise but complete.\n",
    "- Use simple, clear language.\n",
    "- Avoid unnecessary fluff.\n",
    "- Use short paragraphs.\n",
    "- Provide examples when helpful.\n",
    "- Do not assume prior deep knowledge unless asked.\n",
    "\n",
    "Always prioritize clarity over complexity.\n",
    "\"\"\"\n",
    "\n",
    "MAX_CONTEXT_TOKENS = 25000  # simulated context window\n",
    "INPUT_COST_PER_1K = 0.00035\n",
    "OUTPUT_COST_PER_1K = 0.00053\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925770d1",
   "metadata": {},
   "source": [
    "### Memory Store (Structured Gemini Format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc673fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f42f84d",
   "metadata": {},
   "source": [
    "### Cost Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2097ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_cost(prompt_tokens, output_tokens):\n",
    "    input_cost = (prompt_tokens / 1000) * INPUT_COST_PER_1K\n",
    "    output_cost = (output_tokens / 1000) * OUTPUT_COST_PER_1K\n",
    "    return input_cost + output_cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f779905",
   "metadata": {},
   "source": [
    "### Context Trim Function (Using Real Token Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4afd89e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIM_THRESHOLD = 0.8  # 80%\n",
    "\n",
    "def trim_history():\n",
    "    global chat_history\n",
    "    \n",
    "    threshold_limit = MAX_CONTEXT_TOKENS * TRIM_THRESHOLD\n",
    "    \n",
    "    while True:\n",
    "        response = client.models.generate_content(\n",
    "            model=model_name,\n",
    "            contents=chat_history,\n",
    "            config=types.GenerateContentConfig(\n",
    "                system_instruction=SYSTEM_INSTRUCTION,\n",
    "                max_output_tokens=1\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        total_tokens = response.usage_metadata.total_token_count\n",
    "        \n",
    "        if total_tokens <= threshold_limit:\n",
    "            break\n",
    "        \n",
    "        if len(chat_history) >= 2:\n",
    "            chat_history = chat_history[2:]  # remove oldest user+model pair\n",
    "        else:\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4152fde2",
   "metadata": {},
   "source": [
    "### Send Message Function (Full Logic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e002fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_message(user_input):\n",
    "    global chat_history\n",
    "    \n",
    "    # Append user message\n",
    "    chat_history.append(\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[types.Part(text=user_input)]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Trim if needed\n",
    "    trim_history()\n",
    "    \n",
    "    # Generate response\n",
    "    response = client.models.generate_content(\n",
    "        model=model_name,\n",
    "        contents=chat_history,\n",
    "        config=types.GenerateContentConfig(\n",
    "            system_instruction=SYSTEM_INSTRUCTION\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    reply = response.text\n",
    "    \n",
    "    # Append model reply\n",
    "    chat_history.append(\n",
    "        types.Content(\n",
    "            role=\"model\",\n",
    "            parts=[types.Part(text=reply)]\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    usage = response.usage_metadata\n",
    "    \n",
    "    prompt_tokens = usage.prompt_token_count\n",
    "    output_tokens = usage.candidates_token_count\n",
    "    total_tokens = usage.total_token_count\n",
    "    \n",
    "    total_cost = estimate_cost(prompt_tokens, output_tokens)\n",
    "    \n",
    "    print(\"ðŸ¤– Assistant:\", reply)\n",
    "    print(\"Prompt tokens:\", prompt_tokens)\n",
    "    print(\"Output tokens:\", output_tokens)\n",
    "    print(\"Total tokens:\", total_tokens)\n",
    "    print(\"Estimated cost:\", round(total_cost, 6))\n",
    "    print(\"-\" * 50)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67252d8b",
   "metadata": {},
   "source": [
    "### Interactive Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cd3e80bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive Budget-Aware Chatbot\n",
      "Type 'exit' to stop.\n",
      "\n",
      "ðŸ¤– Assistant: Hi Yash! Nice to meet you.\n",
      "\n",
      "How can I help you understand technical concepts today?\n",
      "Prompt tokens: 77\n",
      "Output tokens: 19\n",
      "Total tokens: 96\n",
      "Estimated cost: 3.7e-05\n",
      "--------------------------------------------------\n",
      "ðŸ¤– Assistant: Yes, I do. Your name is Yash.\n",
      "\n",
      "As an AI, I retain information within our current conversation.\n",
      "Prompt tokens: 104\n",
      "Output tokens: 23\n",
      "Total tokens: 209\n",
      "Estimated cost: 4.9e-05\n",
      "--------------------------------------------------\n",
      "Goodbye ðŸ‘‹\n"
     ]
    }
   ],
   "source": [
    "print(\"Interactive Budget-Aware Chatbot\")\n",
    "print(\"Type 'exit' to stop.\\n\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    \n",
    "    if user_input.lower() == \"exit\":\n",
    "        print(\"Goodbye ðŸ‘‹\")\n",
    "        break\n",
    "    \n",
    "    send_message(user_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
